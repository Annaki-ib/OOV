{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSiyBEUcm0Or",
        "outputId": "171c5f82-23d9-462f-85f9-1daac5be2630"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: conllu in /usr/local/lib/python3.11/dist-packages (6.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **data preparation**"
      ],
      "metadata": {
        "id": "IfXDD3OQnfv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFr_KSvTl0nG",
        "outputId": "8b47912e-3a93-485b-f958-0760649b4bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du vocabulaire des mots (Vw) : 1773\n",
            "Taille du vocabulaire des étiquettes (Vi) : 19\n",
            "Nombre de phrases encodées : 803\n",
            "Vocabulaires sauvegardés dans le dossier 'vocab'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from collections import defaultdict, Counter\n",
        "import torch\n",
        "from conllu import parse_incr\n",
        "\n",
        "# Constantes\n",
        "PAD_ID = 0  # Indice pour le padding\n",
        "UNK_ID = 1  # Indice pour les mots hors vocabulaire (OOV)\n",
        "\n",
        "def build_vocab(data_file, min_freq=1):\n",
        "    \"\"\"\n",
        "    Construit les vocabulaires des mots (Vw) et des étiquettes (Vi) à partir du fichier de données.\n",
        "    :param data_file: Chemin vers le fichier de données au format CoNLL-U.\n",
        "    :param min_freq: Fréquence minimale pour qu'un mot soit inclus dans le vocabulaire.\n",
        "    :return: Deux dictionnaires : Vw (mots) et Vi (étiquettes POS).\n",
        "    \"\"\"\n",
        "    word_counter = Counter()  # Compteur pour les mots\n",
        "    pos_counter = Counter()   # Compteur pour les étiquettes POS\n",
        "\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            for token in sentence:\n",
        "                word = token[\"form\"].lower()  # On utilise des minuscules pour normaliser\n",
        "                pos = token[\"upos\"]\n",
        "                word_counter[word] += 1\n",
        "                pos_counter[pos] += 1\n",
        "\n",
        "    # Construction du vocabulaire des mots (Vw)\n",
        "    Vw = {\"<PAD>\": PAD_ID, \"<UNK>\": UNK_ID}  # On ajoute les tokens spéciaux\n",
        "    for word, freq in word_counter.items():\n",
        "        if freq >= min_freq:  # On ignore les mots trop rares\n",
        "            Vw[word] = len(Vw)  # On assigne un nouvel indice\n",
        "\n",
        "    # Construction du vocabulaire des étiquettes (Vi)\n",
        "    Vi = {\"<PAD>\": PAD_ID}  # On ajoute le token spécial pour le padding\n",
        "    for pos in pos_counter:\n",
        "        Vi[pos] = len(Vi)  # On assigne un nouvel indice\n",
        "\n",
        "    return Vw, Vi\n",
        "\n",
        "def encode_data(data_file, Vw, Vi):\n",
        "    \"\"\"\n",
        "    Encode les mots et les étiquettes POS en indices à l'aide des vocabulaires Vw et Vi.\n",
        "    :param data_file: Chemin vers le fichier de données au format CoNLL-U.\n",
        "    :param Vw: Vocabulaire des mots.\n",
        "    :param Vi: Vocabulaire des étiquettes POS.\n",
        "    :return: Une liste de tuples (mots encodés, étiquettes encodées).\n",
        "    \"\"\"\n",
        "    encoded_data = []\n",
        "\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            words = []\n",
        "            pos_tags = []\n",
        "            for token in sentence:\n",
        "                word = token[\"form\"].lower()  # On utilise des minuscules pour normaliser\n",
        "                pos = token[\"upos\"]\n",
        "                # Encodage des mots (remplacement des OOV par UNK_ID)\n",
        "                word_idx = Vw.get(word, UNK_ID)\n",
        "                pos_idx = Vi[pos]\n",
        "                words.append(word_idx)\n",
        "                pos_tags.append(pos_idx)\n",
        "            encoded_data.append((words, pos_tags))\n",
        "\n",
        "    return encoded_data\n",
        "\n",
        "def save_vocab(Vw, Vi, output_dir):\n",
        "    \"\"\"\n",
        "    Sauvegarde les vocabulaires Vw et Vi dans des fichiers.\n",
        "    :param Vw: Vocabulaire des mots.\n",
        "    :param Vi: Vocabulaire des étiquettes POS.\n",
        "    :param output_dir: Répertoire de sortie pour sauvegarder les fichiers.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Sauvegarde du vocabulaire des mots\n",
        "    with open(os.path.join(output_dir, \"vocab_words.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        for word, idx in Vw.items():\n",
        "            f.write(f\"{word}\\t{idx}\\n\")\n",
        "\n",
        "    # Sauvegarde du vocabulaire des étiquettes\n",
        "    with open(os.path.join(output_dir, \"vocab_pos.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        for pos, idx in Vi.items():\n",
        "            f.write(f\"{pos}\\t{idx}\\n\")\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"\n",
        "    Charge un vocabulaire à partir d'un fichier.\n",
        "    :param vocab_file: Chemin vers le fichier de vocabulaire.\n",
        "    :return: Un dictionnaire représentant le vocabulaire.\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            word, idx = line.strip().split(\"\\t\")\n",
        "            vocab[word] = int(idx)\n",
        "    return vocab\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Chemin vers le fichier de données d'entraînement\n",
        "    train_file = \"/content/fr_partut-ud-train.conllu\"\n",
        "\n",
        "    # Étape 1 : Construire les vocabulaires\n",
        "    Vw, Vi = build_vocab(train_file, min_freq=2)  # On ignore les mots qui apparaissent moins de 2 fois\n",
        "    print(f\"Taille du vocabulaire des mots (Vw) : {len(Vw)}\")\n",
        "    print(f\"Taille du vocabulaire des étiquettes (Vi) : {len(Vi)}\")\n",
        "\n",
        "    # Étape 2 : Encoder les données d'entraînement\n",
        "    encoded_train_data = encode_data(train_file, Vw, Vi)\n",
        "    print(f\"Nombre de phrases encodées : {len(encoded_train_data)}\")\n",
        "\n",
        "    # Étape 3 : Sauvegarder les vocabulaires\n",
        "    save_vocab(Vw, Vi, \"vocab\")\n",
        "    print(\"Vocabulaires sauvegardés dans le dossier 'vocab'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "import torch\n",
        "from conllu import parse_incr\n",
        "\n",
        "# Constantes\n",
        "PAD_ID = 0  # Padding\n",
        "UNK_ID = 1  # Out-of-vocabulary\n",
        "\n",
        "def build_vocab(data_file, min_freq=1):\n",
        "    \"\"\"\n",
        "    Construit les vocabulaires des mots (Vw) et des étiquettes (Vi).\n",
        "    \"\"\"\n",
        "    word_counter = Counter()\n",
        "    pos_counter = Counter()\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            for token in sentence:\n",
        "                word = token[\"form\"].lower()\n",
        "                pos = token[\"upos\"]\n",
        "                word_counter[word] += 1\n",
        "                pos_counter[pos] += 1\n",
        "\n",
        "    Vw = {\"<PAD>\": PAD_ID, \"<UNK>\": UNK_ID}\n",
        "    for word, freq in word_counter.items():\n",
        "        if freq >= min_freq:\n",
        "            Vw[word] = len(Vw)\n",
        "\n",
        "    Vi = {\"<PAD>\": PAD_ID}\n",
        "    for pos in pos_counter:\n",
        "        Vi[pos] = len(Vi)\n",
        "\n",
        "    return Vw, Vi\n",
        "\n",
        "def encode_data(data_file, Vw, Vi):\n",
        "    \"\"\"\n",
        "    Encode les phrases et leurs étiquettes en indices.\n",
        "    \"\"\"\n",
        "    encoded_data = []\n",
        "    with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            word_indices = []\n",
        "            pos_indices = []\n",
        "            for token in sentence:\n",
        "                word = token[\"form\"].lower()\n",
        "                pos = token[\"upos\"]\n",
        "                word_idx = Vw.get(word, UNK_ID)\n",
        "                pos_idx = Vi[pos]\n",
        "                word_indices.append(word_idx)\n",
        "                pos_indices.append(pos_idx)\n",
        "            encoded_data.append((word_indices, pos_indices))\n",
        "    return encoded_data\n",
        "\n",
        "def pad_batch(batch, pad_value=PAD_ID):\n",
        "    \"\"\"\n",
        "    Applique le padding à une liste de séquences de longueurs variables.\n",
        "    \"\"\"\n",
        "    from torch.nn.utils.rnn import pad_sequence\n",
        "    batch_tensors = [torch.tensor(seq, dtype=torch.long) for seq in batch]\n",
        "    padded_batch = pad_sequence(batch_tensors, batch_first=True, padding_value=pad_value)\n",
        "    return padded_batch\n",
        "\n",
        "def save_vocab(Vw, Vi, output_dir):\n",
        "    \"\"\"\n",
        "    Sauvegarde les vocabulaires dans des fichiers.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    with open(os.path.join(output_dir, \"vocab_words.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        for word, idx in Vw.items():\n",
        "            f.write(f\"{word}\\t{idx}\\n\")\n",
        "    with open(os.path.join(output_dir, \"vocab_pos.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        for pos, idx in Vi.items():\n",
        "            f.write(f\"{pos}\\t{idx}\\n\")\n",
        "\n",
        "def load_vocab(vocab_file):\n",
        "    \"\"\"\n",
        "    Charge un vocabulaire depuis un fichier.\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            token, idx = line.strip().split(\"\\t\")\n",
        "            vocab[token] = int(idx)\n",
        "    return vocab\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Chemin vers le fichier de données d'entraînement\n",
        "    train_file = \"/content/fr_partut-ud-train.conllu\"\n",
        "\n",
        "    # Étape 1 : Construire les vocabulaires\n",
        "    Vw, Vi = build_vocab(train_file, min_freq=2)  # On ignore les mots qui apparaissent moins de 2 fois\n",
        "    print(f\"Taille du vocabulaire des mots (Vw) : {len(Vw)}\")\n",
        "    print(f\"Taille du vocabulaire des étiquettes (Vi) : {len(Vi)}\")\n",
        "\n",
        "    # Étape 2 : Encoder les données d'entraînement\n",
        "    encoded_train_data = encode_data(train_file, Vw, Vi)\n",
        "    print(f\"Nombre de phrases encodées : {len(encoded_train_data)}\")\n",
        "\n",
        "    # Étape 3 : Sauvegarder les vocabulaires\n",
        "    save_vocab(Vw, Vi, \"vocab\")\n",
        "    print(\"Vocabulaires sauvegardés dans le dossier 'vocab'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVMpISTynMBo",
        "outputId": "7d4d28db-239e-47fd-e51e-130c33451221"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du vocabulaire des mots (Vw) : 1773\n",
            "Taille du vocabulaire des étiquettes (Vi) : 19\n",
            "Nombre de phrases encodées : 803\n",
            "Vocabulaires sauvegardés dans le dossier 'vocab'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class POSTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, padding_idx=0, dropout=0.5):\n",
        "        super(POSTagger, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x de taille (batch_size, seq_len)\n",
        "        embeds = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
        "        gru_out, _ = self.gru(embeds)  # (batch_size, seq_len, hidden_dim)\n",
        "        gru_out = self.dropout(gru_out)\n",
        "        logits = self.fc(gru_out)  # (batch_size, seq_len, tagset_size)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "ANDlcdK7rekL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "# Création d'un Dataset personnalisé\n",
        "class POSDataset(Dataset):\n",
        "    def __init__(self, encoded_data):\n",
        "        self.encoded_data = encoded_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "\n",
        "# Fonction de collate pour le DataLoader\n",
        "def collate_fn(batch):\n",
        "    words = [item[0] for item in batch]\n",
        "    tags = [item[1] for item in batch]\n",
        "    padded_words = pad_batch(words, pad_value=PAD_ID)\n",
        "    padded_tags = pad_batch(tags, pad_value=PAD_ID)\n",
        "    return padded_words, padded_tags\n",
        "\n",
        "# Fonction d'entraînement sur une époque\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for words, tags in dataloader:\n",
        "        words = words.to(device)\n",
        "        tags = tags.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(words)  # (batch, seq, tagset_size)\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "        loss = criterion(outputs, tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Fonction d'évaluation sur le set dev\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total_tokens = 0\n",
        "    with torch.no_grad():\n",
        "        for words, tags in dataloader:\n",
        "            words = words.to(device)\n",
        "            tags = tags.to(device)\n",
        "            outputs = model(words)\n",
        "            outputs = outputs.view(-1, outputs.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "            loss = criterion(outputs, tags)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = outputs.argmax(dim=1)\n",
        "            mask = tags != PAD_ID\n",
        "            correct += (predictions[mask] == tags[mask]).sum().item()\n",
        "            total_tokens += mask.sum().item()\n",
        "    accuracy = correct / total_tokens if total_tokens > 0 else 0\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Chemins vers les fichiers\n",
        "    train_file = \"/content/fr_partut-ud-train.conllu\"\n",
        "    dev_file = \"/content/fr_partut-ud-dev.conllu\"\n",
        "\n",
        "    # Hyperparamètres\n",
        "    embedding_dim = 100\n",
        "    hidden_dim = 128\n",
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    learning_rate = 0.001\n",
        "    min_freq = 2\n",
        "    dropout = 0.5\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Construction des vocabulaires à partir du fichier d'entraînement\n",
        "    Vw, Vi = build_vocab(train_file, min_freq)\n",
        "    print(f\"Taille du vocabulaire des mots : {len(Vw)}\")\n",
        "    print(f\"Taille du vocabulaire des étiquettes : {len(Vi)}\")\n",
        "\n",
        "    # Sauvegarde des vocabulaires\n",
        "    save_vocab(Vw, Vi, \"vocab\")\n",
        "\n",
        "    # Encodage des données d'entraînement et de développement\n",
        "    train_data = encode_data(train_file, Vw, Vi)\n",
        "    dev_data = encode_data(dev_file, Vw, Vi)\n",
        "\n",
        "    train_dataset = POSDataset(train_data)\n",
        "    dev_dataset = POSDataset(dev_data)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Initialisation du modèle, de la fonction de perte et de l'optimiseur\n",
        "    model = POSTagger(vocab_size=len(Vw), tagset_size=len(Vi),\n",
        "                      embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
        "                      padding_idx=PAD_ID, dropout=dropout)\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_ID)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Boucle d'entraînement\n",
        "    for epoch in range(1, epochs+1):\n",
        "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "        dev_loss, dev_accuracy = evaluate(model, dev_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch}: train loss = {train_loss:.4f}, dev loss = {dev_loss:.4f}, dev accuracy = {dev_accuracy:.4f}\")\n",
        "\n",
        "    # Sauvegarde du modèle et des paramètres nécessaires\n",
        "    model_state = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'Vw': Vw,\n",
        "        'Vi': Vi,\n",
        "        'embedding_dim': embedding_dim,\n",
        "        'hidden_dim': hidden_dim,\n",
        "        'PAD_ID': PAD_ID,\n",
        "        'UNK_ID': UNK_ID\n",
        "    }\n",
        "    torch.save(model_state, \"pos_tagger.pt\")\n",
        "    print(\"Modèle sauvegardé dans pos_tagger.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1riWtIrjKl",
        "outputId": "c535dad8-372b-44b3-caf1-e7eb0c245a65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taille du vocabulaire des mots : 1773\n",
            "Taille du vocabulaire des étiquettes : 19\n",
            "Epoch 1: train loss = 2.3893, dev loss = 1.7862, dev accuracy = 0.5735\n",
            "Epoch 2: train loss = 1.4724, dev loss = 1.1865, dev accuracy = 0.6762\n",
            "Epoch 3: train loss = 1.0738, dev loss = 0.9270, dev accuracy = 0.7435\n",
            "Epoch 4: train loss = 0.8637, dev loss = 0.7823, dev accuracy = 0.7815\n",
            "Epoch 5: train loss = 0.7428, dev loss = 0.6939, dev accuracy = 0.7972\n",
            "Epoch 6: train loss = 0.6568, dev loss = 0.6397, dev accuracy = 0.8076\n",
            "Epoch 7: train loss = 0.6012, dev loss = 0.5882, dev accuracy = 0.8253\n",
            "Epoch 8: train loss = 0.5468, dev loss = 0.5512, dev accuracy = 0.8347\n",
            "Epoch 9: train loss = 0.4878, dev loss = 0.5253, dev accuracy = 0.8425\n",
            "Epoch 10: train loss = 0.4453, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Modèle sauvegardé dans pos_tagger.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from conllu import parse_incr\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    Vw = checkpoint['Vw']\n",
        "    Vi = checkpoint['Vi']\n",
        "    embedding_dim = checkpoint['embedding_dim']\n",
        "    hidden_dim = checkpoint['hidden_dim']\n",
        "    model = POSTagger(vocab_size=len(Vw), tagset_size=len(Vi),\n",
        "                      embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
        "                      padding_idx=PAD_ID)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model, Vw, Vi\n",
        "\n",
        "def predict_sentence(model, sentence, Vw, Vi, device):\n",
        "    # Extraction des mots et conversion en indices\n",
        "    words = [token['form'].lower() for token in sentence]\n",
        "    word_indices = [Vw.get(word, UNK_ID) for word in words]\n",
        "    input_tensor = torch.tensor(word_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)  # (1, seq_len, tagset_size)\n",
        "        predictions = outputs.argmax(dim=-1).squeeze(0).cpu().tolist()\n",
        "    # Création d'un dictionnaire inverse pour les étiquettes\n",
        "    rev_Vi = {idx: tag for tag, idx in Vi.items()}\n",
        "    predicted_tags = [rev_Vi.get(idx, \"UNK\") for idx in predictions]\n",
        "    return predicted_tags\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import sys\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_path = \"/content/pos_tagger.pt\"\n",
        "\n",
        "    # Chargement du modèle et des vocabulaires\n",
        "    model, Vw, Vi = load_model(model_path, device)\n",
        "\n",
        "    # Chemin du fichier à traiter (par exemple dev ou test)\n",
        "    file_path = \"/content/fr_partut-ud-test.conllu\"\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            predicted_tags = predict_sentence(model, sentence, Vw, Vi, device)\n",
        "            tokens = [token[\"form\"] for token in sentence]\n",
        "            print(\"Sentence :\", \" \".join(tokens))\n",
        "            print(\"Predicted POS :\", \" \".join(predicted_tags))\n",
        "            print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcpOVbV-r7O3",
        "outputId": "402ed00e-1d17-44b9-ee9d-7a3938658cca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0fb7f0e20024>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence : Paternité - Partage des de les conditions initiales à l' identique 2.0 .\n",
            "Predicted POS : NOUN PUNCT DET _ ADP DET NOUN ADJ ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Toute utilisation de l' Oeuvre autrement qu' explicitement autorisée selon ce contrat ou le droit applicable est interdite .\n",
            "Predicted POS : DET NOUN ADP DET NOUN ADJ SCONJ VERB VERB ADP PRON NOUN CCONJ DET NOUN ADJ AUX VERB PUNCT\n",
            "---\n",
            "Sentence : À l' exception des de les situations expressément mentionnées dans le présent contrat ou dans un autre accord écrit , ou exigées par la loi applicable , l' oeuvre est mise à disposition en l' état sans garantie d' aucune sorte , qu' elle soit expresse ou tacite , y compris à l' égard du de le contenu ou de l' exactitude de l' oeuvre .\n",
            "Predicted POS : ADP DET NOUN _ ADP DET NOUN ADJ ADJ ADP DET ADJ NOUN CCONJ ADP DET NOUN NOUN ADJ PUNCT CCONJ VERB ADP DET NOUN ADJ PUNCT DET NOUN AUX VERB ADP NOUN ADP DET NOUN ADP ADJ ADP NOUN NOUN PUNCT SCONJ PRON AUX VERB CCONJ VERB PUNCT PRON VERB ADP DET NOUN _ ADP DET NOUN CCONJ ADP DET NOUN ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Creative Commons n' est pas partie à ce contrat et n' offre aucune forme de garantie relative à l' oeuvre .\n",
            "Predicted POS : NOUN PROPN PART AUX ADV VERB ADP DET NOUN CCONJ PART VERB DET NOUN ADP ADJ VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Oui , monsieur Evans , je pense qu' une initiative dans le sens que vous venez de suggérer serait tout à fait appropriée .\n",
            "Predicted POS : VERB PUNCT NOUN VERB PUNCT PRON VERB SCONJ DET NOUN ADP DET NOUN SCONJ PRON VERB ADP VERB ADP DET ADP VERB VERB PUNCT\n",
            "---\n",
            "Sentence : Je demande que cette décision soit reconsidérée car ce n' est pas le cas .\n",
            "Predicted POS : PRON VERB SCONJ DET NOUN AUX VERB CCONJ PRON PART AUX ADV DET NOUN PUNCT\n",
            "---\n",
            "Sentence : La sécurité des de les transports a malheureusement fait l' actualité ces derniers temps :\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN AUX VERB ADJ DET NOUN DET PRON VERB PUNCT\n",
            "---\n",
            "Sentence : L' importance de la sécurité sur la route , sur les rails ou sur les voies navigables est naturellement primordiale et en raison du de le caractère international de ces modes de transport , nous devons également harmoniser les formations des de les conseillers à la sécurité , ainsi que , notamment , les exigences du de le nouvel Adr qui devrait bientôt entrer en vigueur .\n",
            "Predicted POS : DET NOUN ADP DET NOUN ADP DET NOUN PUNCT ADP DET NOUN CCONJ ADP DET NOUN ADJ AUX ADV VERB CCONJ ADP NOUN _ ADP DET NOUN ADJ ADP DET NOUN ADP NOUN PUNCT PRON VERB ADV VERB DET NOUN _ ADP DET NOUN ADP DET NOUN PUNCT ADV SCONJ PUNCT ADV PUNCT DET NOUN _ ADP DET NOUN ADJ PRON VERB VERB VERB ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : La faute n' en revient certes pas à la seule commission mais je pense que nous devons réagir plus vite pour parvenir à une harmonisation dans ce domaine aussi .\n",
            "Predicted POS : DET NOUN PART ADP VERB ADJ ADV ADP DET NOUN NOUN CCONJ PRON VERB SCONJ PRON VERB VERB ADV ADJ ADP VERB ADP DET NOUN ADP DET NOUN ADV PUNCT\n",
            "---\n",
            "Sentence : Je peux m' accommoder de ces normes minimales mais je prie la commission de suivre ce dossier avec une réelle attention .\n",
            "Predicted POS : PRON VERB PRON VERB ADP DET NOUN ADJ CCONJ PRON VERB DET NOUN ADP VERB DET NOUN ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Je pense toutefois que nous devrions tout faire pour limiter autant que possible le transport de marchandises dangereuses , et ce dans l' ensemble des de les pays , qu' ils soient des régions de transit ou non .\n",
            "Predicted POS : PRON VERB ADV SCONJ PRON VERB ADV VERB ADP VERB DET SCONJ ADJ DET NOUN ADP NOUN ADJ PUNCT CCONJ PRON ADP DET NOUN _ ADP DET NOUN PUNCT SCONJ PRON AUX DET NOUN ADP NOUN CCONJ ADV PUNCT\n",
            "---\n",
            "Sentence : J' espère que ma proposition sera prise en considération lors du de le vote de demain .\n",
            "Predicted POS : PRON VERB SCONJ PRON NOUN NOUN VERB ADP NOUN ADV _ ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Je voudrais demander à la vice - présidente si elle peut nous dire où en sont les efforts d' harmonisation déployés par ces deux organisations et si l' Ue a la possibilité d' accélérer ces efforts en appliquant des principes aussi simples que possibles .\n",
            "Predicted POS : PRON VERB VERB ADP DET NOUN PUNCT NOUN SCONJ PRON VERB PRON VERB PRON ADP AUX DET NOUN ADP NOUN ADJ ADP DET NOUN ADJ CCONJ SCONJ DET NOUN AUX DET NOUN ADP NOUN DET NOUN ADP NOUN _ NOUN NOUN ADJ SCONJ VERB PUNCT\n",
            "---\n",
            "Sentence : Monsieur le président , je souhaite vivement remercier mme Schroedter pour le travail qu' elle a accompli dans ce domaine et expliquer aux à les députés que j' interviens au à le nom de ma collègue , mme Flautre , qui a suivi ce sujet pour la commission de l' emploi et des de les affaires sociales mais qui est hélas malade .\n",
            "Predicted POS : NOUN DET NOUN PUNCT PRON VERB VERB VERB NOUN NOUN ADP DET NOUN SCONJ PRON AUX VERB ADP DET NOUN CCONJ ADJ _ ADP DET NOUN SCONJ PRON VERB _ ADP DET NOUN ADP NOUN NOUN PUNCT NOUN ADJ PUNCT PRON AUX VERB PRON NOUN ADP DET NOUN ADP DET NOUN CCONJ _ ADP DET NOUN NOUN CCONJ PRON AUX VERB VERB PUNCT\n",
            "---\n",
            "Sentence : Mais le manque de lignes directrices est ici particulièrement regrettable , alors que l' idée de lier les interventions du de le fond social à la stratégie de l' emploi sera appliquée pour la première fois lors de la période du de le programme 2000 - 2006 .\n",
            "Predicted POS : CCONJ DET NOUN ADP NOUN ADJ AUX VERB DET NOUN PUNCT ADV SCONJ DET NOUN ADP NOUN DET NOUN _ ADP DET NOUN ADJ ADP DET NOUN ADP DET NOUN AUX VERB ADP DET NOUN NOUN ADV ADP DET NOUN _ ADP DET NOUN NOUN PUNCT PUNCT PUNCT\n",
            "---\n",
            "Sentence : Mais la vérité est que nous estimons , et cela se reflète dans la formulation des de les conclusions , que la commission doit tenir compte de ce qui est approuvé au à le parlement , essentiellement en ce qui concerne la révision de ces orientations en milieu de période .\n",
            "Predicted POS : CCONJ DET NOUN AUX SCONJ PRON VERB PUNCT CCONJ VERB PRON VERB ADP DET NOUN _ ADP DET NOUN PUNCT SCONJ DET NOUN VERB VERB NOUN ADP DET PRON AUX VERB _ ADP DET NOUN PUNCT NOUN ADP PRON PRON VERB DET NOUN ADP DET NOUN ADP NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Monsieur le président , monsieur le commissaire , chers collègues , je tiens à remercier mme Schroedter pour son excellent rapport ;\n",
            "Predicted POS : NOUN DET NOUN PUNCT NOUN DET NOUN PUNCT ADJ NOUN PUNCT PRON VERB ADP VERB NOUN NOUN ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : elle s' est consacrée à fond à sa tâche et , lors de l' examen en commission , a tenu compte des de les nombreux amendements qui ont été apportés .\n",
            "Predicted POS : PRON PRON AUX VERB ADP NOUN ADP DET NOUN CCONJ PUNCT ADV ADP DET NOUN ADP NOUN PUNCT AUX VERB NOUN _ ADP DET NOUN ADJ PRON AUX AUX VERB PUNCT\n",
            "---\n",
            "Sentence : On y a intégré des questions de détail et des de les questions qui ont déjà été abordées dans des rapports antérieurs .\n",
            "Predicted POS : PRON PRON AUX VERB DET NOUN ADP NOUN CCONJ _ ADP DET NOUN PRON AUX ADV AUX VERB ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : C' est une histoire qui dure depuis cinq ans que je suis député au à le parlement , et j' ai abordé à maintes reprises cette question .\n",
            "Predicted POS : PRON AUX DET NOUN PRON VERB ADP VERB NOUN SCONJ PRON AUX VERB _ ADP DET NOUN PUNCT CCONJ PRON VERB VERB ADP VERB VERB DET NOUN PUNCT\n",
            "---\n",
            "Sentence : En conséquence , il me semble qu' il doit anticiper et établir les lignes directrices de la révision à mi - parcours de 2003 , voire influencer la seconde phase de programmation qui suivra 2003 .\n",
            "Predicted POS : ADP NOUN PUNCT PRON VERB VERB SCONJ PRON VERB VERB CCONJ VERB DET NOUN ADJ ADP DET NOUN ADP VERB PUNCT ADJ ADP NOUN PUNCT VERB ADJ DET NOUN ADJ ADP NOUN PRON VERB VERB PUNCT\n",
            "---\n",
            "Sentence : sa mise en oeuvre impliquerait certainement une extension d' instruments de redistribution comme les fonds structurels .\n",
            "Predicted POS : DET NOUN ADP NOUN VERB ADJ DET NOUN ADP NOUN ADP NOUN ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Monsieur le président , je voudrais également féliciter le rapporteur pour son excellent travail .\n",
            "Predicted POS : NOUN DET NOUN PUNCT PRON VERB ADV VERB DET NOUN ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Je conclus , Monsieur le Président , en affirmant qu' il est assez grave que la Commission , dans sa communication , n' ait porté que peu attention aux à les pactes territoriaux et surtout aux à les modalités de lutte contre le chômage chez les femmes et les jeunes .\n",
            "Predicted POS : PRON VERB PUNCT NOUN DET NOUN PUNCT ADP NOUN SCONJ PRON AUX ADV VERB SCONJ DET NOUN PUNCT ADP DET NOUN PUNCT PART AUX VERB SCONJ ADV NOUN _ ADP DET NOUN ADJ CCONJ AUX _ ADP DET NOUN ADP NOUN ADP DET NOUN NOUN DET NOUN CCONJ DET NOUN PUNCT\n",
            "---\n",
            "Sentence : ANA a utilisé une série de mots clés pour cibler les utilisateurs spécialement intéressés par le voyage et la culture japonaise .\n",
            "Predicted POS : ADV AUX VERB DET NOUN ADP NOUN ADJ ADP VERB DET NOUN ADJ ADJ ADP DET NOUN CCONJ DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Vous pouvez désormais voir les mises à jour publiques des de les personnes qui vous intéressent , sans pour autant les ajouter à votre liste d' amis .\n",
            "Predicted POS : PRON VERB VERB VERB DET NOUN ADP NOUN ADJ _ ADP DET NOUN PRON PRON VERB PUNCT ADP ADP VERB DET NOUN ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Si vous ne voyez pas ce bouton , c' est que vous ne pouvez pas vous abonner .\n",
            "Predicted POS : SCONJ PRON PART VERB ADV DET NOUN PUNCT PRON AUX SCONJ PRON PART VERB ADV PRON VERB PUNCT\n",
            "---\n",
            "Sentence : Vous avez une page Facebook ?\n",
            "Predicted POS : PRON VERB DET NOUN PROPN PUNCT\n",
            "---\n",
            "Sentence : ( 14 ) En règle générale , la consommation d' énergie des de les produits consommateurs d' énergie en mode veille ou arrêt doit être réduite au à le minimum nécessaire pour leur bon fonctionnement .\n",
            "Predicted POS : PUNCT NUM PUNCT ADP NOUN VERB PUNCT DET NOUN ADP NOUN _ ADP DET NOUN NOUN ADP NOUN ADP NOUN ADJ CCONJ NOUN VERB AUX VERB _ ADP DET NOUN NOUN ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : - le programme doit être reconduit pour une nouvelle période d' au à le moins quatre ans , assortie d' un budget équivalent ( 1 million d' euros par an ) et doit porter sur les mêmes mesures et les mêmes destinataires ;\n",
            "Predicted POS : PUNCT DET NOUN VERB AUX VERB ADP DET ADJ ADJ ADP _ ADP DET NOUN ADJ NOUN PUNCT VERB ADP DET NOUN ADJ PUNCT NUM NUM ADP NOUN ADP DET PUNCT CCONJ VERB VERB ADP DET NOUN NOUN CCONJ DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : 2 . Toute personne a le droit de quitter tout pays , y compris le sien , et de revenir dans son pays .\n",
            "Predicted POS : NUM PUNCT DET NOUN AUX DET NOUN ADP NOUN DET NOUN PUNCT PRON VERB DET NOUN PUNCT CCONJ ADP VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : 1 . À partir de l' âge nubile , l' homme et la femme , sans aucune restriction quant à la race , la nationalité ou la religion , ont le droit de se marier et de fonder une famille .\n",
            "Predicted POS : NUM PUNCT ADP VERB ADP DET NOUN ADJ PUNCT DET NOUN CCONJ DET NOUN PUNCT ADP DET NOUN ADV ADP DET NOUN PUNCT DET NOUN CCONJ DET NOUN PUNCT AUX DET NOUN ADP PRON VERB CCONJ ADP VERB DET NOUN PUNCT\n",
            "---\n",
            "Sentence : 2 . Toute personne a droit à accéder , dans des conditions d' égalité , aux à les fonctions publiques de son pays .\n",
            "Predicted POS : NUM PUNCT DET NOUN AUX NOUN ADP VERB PUNCT ADP DET NOUN ADP NOUN PUNCT _ ADP DET NOUN ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : 3 . Quiconque travaille a droit à une rémunération équitable et satisfaisante lui assurant ainsi qu' à sa famille une existence conforme à la dignité humaine et complétée , s' il y a lieu , par tous autres moyens de protection sociale .\n",
            "Predicted POS : NUM PUNCT VERB VERB AUX NOUN ADP DET NOUN ADJ CCONJ ADJ ADP VERB ADV SCONJ ADP DET NOUN DET NOUN ADJ ADP DET NOUN ADJ CCONJ ADJ PUNCT PRON PRON PRON VERB VERB PUNCT ADP DET ADJ NOUN ADP NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Si maman n' est pas contente , personne n' est content .\n",
            "Predicted POS : SCONJ NOUN PART AUX ADV VERB PUNCT NOUN PART AUX VERB PUNCT\n",
            "---\n",
            "Sentence : La République de Bulgarie et la Roumanie deviennent membres de l' Union Européenne .\n",
            "Predicted POS : DET NOUN ADP NOUN CCONJ DET NOUN ADJ NOUN ADP DET PROPN PROPN PUNCT\n",
            "---\n",
            "Sentence : Les conditions et modalités de l' admission figurent dans le protocole annexé au à le présent traité .\n",
            "Predicted POS : DET NOUN CCONJ VERB ADP DET NOUN ADJ ADP DET NOUN ADJ _ ADP DET ADJ PUNCT PUNCT\n",
            "---\n",
            "Sentence : Les dispositions de ce protocole font partie intégrante du de le présent traité .\n",
            "Predicted POS : DET NOUN ADP DET NOUN ADV NOUN ADJ _ ADP DET ADJ PUNCT PUNCT\n",
            "---\n",
            "Sentence : Les dispositions de cet acte font partie intégrante du de le présent traité .\n",
            "Predicted POS : DET NOUN ADP DET NOUN ADJ NOUN ADJ _ ADP DET ADJ PUNCT PUNCT\n",
            "---\n",
            "Sentence : Le présent traité est ratifié par les Hautes Parties Contractantes , conformément à leurs règles constitutionnelles respectives .\n",
            "Predicted POS : DET ADJ PUNCT AUX VERB ADP DET NOUN ADJ ADJ PUNCT ADV ADP DET NOUN VERB VERB PUNCT\n",
            "---\n",
            "Sentence : Les instruments de ratification sont déposés auprès du de le gouvernement de la République italienne au à le plus tard le 31 décembre 2006 .\n",
            "Predicted POS : DET NOUN ADP NOUN AUX VERB PRON _ ADP DET NOUN ADP DET NOUN ADJ _ ADP DET ADV ADJ DET NOUN ADJ VERB PUNCT\n",
            "---\n",
            "Sentence : Le présent traité entre en vigueur le 1er janvier 2007 à condition que tous les instruments de ratification aient été déposés avant cette date .\n",
            "Predicted POS : DET ADJ PUNCT ADP ADP VERB DET NOUN ADJ ADJ ADP NOUN SCONJ DET DET NOUN ADP NOUN ADJ AUX VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Si une telle décision est prise à l' égard d' un seul des de les états adhérents , le présent traité entre en vigueur pour ledit état le 1 janvier 2008 .\n",
            "Predicted POS : SCONJ DET NOUN NOUN AUX VERB ADP DET NOUN ADP DET ADJ _ ADP DET NOUN ADJ PUNCT DET ADJ PUNCT ADP ADP VERB ADP VERB NOUN DET NUM NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Ces mesures n' entrent en vigueur que sous réserve et à la date de l' entrée en vigueur du de le présent traité .\n",
            "Predicted POS : DET NOUN PART VERB ADP NOUN SCONJ ADP NOUN CCONJ ADP DET NOUN ADP DET NOUN ADP NOUN _ ADP DET ADJ PUNCT PUNCT\n",
            "---\n",
            "Sentence : Le texte du de le traité établissant une constitution pour l' Europe , rédigé en langues bulgare et roumaine , est annexé au à le présent traité .\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN ADJ DET NOUN ADP DET PROPN PUNCT VERB ADP NOUN ADJ CCONJ ADJ PUNCT AUX VERB _ ADP DET ADJ PUNCT PUNCT\n",
            "---\n",
            "Sentence : Protocole relatif aux à les conditions et modalités d' admission de la République de Bulgarie et de la Roumanie à l' Union Européenne .\n",
            "Predicted POS : VERB ADP _ ADP DET NOUN CCONJ ADJ ADP NOUN ADP DET NOUN ADP NOUN CCONJ ADP DET NOUN ADP DET NOUN PROPN PUNCT\n",
            "---\n",
            "Sentence : La Bulgarie et la Roumanie adhèrent aux à les décisions et accords adoptés par les représentants des de les gouvernements des de les états membres réunis au à le sein du de le conseil .\n",
            "Predicted POS : DET NOUN CCONJ DET NOUN ADJ _ ADP DET NOUN CCONJ ADJ VERB ADP DET NOUN _ ADP DET NOUN _ ADP DET NOUN NOUN VERB _ ADP DET NOUN _ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Parmi les instruments particuliers mentionnés dans le présent article figurent ceux qui sont visés à l' article IV-438 de la constitution .\n",
            "Predicted POS : ADP DET NOUN ADJ VERB ADP DET ADJ NOUN NOUN PUNCT PRON AUX VERB ADP DET NOUN ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : La commission soumet les projets de protocoles au à le conseil pour qu' ils soient conclus .\n",
            "Predicted POS : DET NOUN VERB DET NOUN ADP NOUN _ ADP DET NOUN ADP SCONJ PRON AUX VERB PUNCT\n",
            "---\n",
            "Sentence : Le conseil statue à l' unanimité , après consultation du de le parlement européen .\n",
            "Predicted POS : DET NOUN VERB ADP DET NOUN PUNCT ADP NOUN _ ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : L' application de la constitution et des de les actes adoptés par les institutions fait l' objet , à titre transitoire , des de les dispositions dérogatoires prévues par le présent protocole .\n",
            "Predicted POS : DET NOUN ADP DET NOUN CCONJ _ ADP DET NOUN ADJ ADP DET NOUN ADJ DET NOUN PUNCT ADP VERB VERB PUNCT DET ADP DET NOUN ADJ VERB ADP DET ADJ NOUN PUNCT\n",
            "---\n",
            "Sentence : Par dérogation à ce qui précède , les procédures de marchés publics engagées après l' adhésion respectent les dispositions pertinentes de l' union .\n",
            "Predicted POS : ADP NOUN ADP PRON PRON VERB PUNCT DET NOUN ADP NOUN ADV VERB ADP DET NOUN VERB DET NOUN ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le dernier exercice de programmation de l' aide de préadhésion visée au à le paragraphe 1 a lieu pendant la dernière année précédant l' adhésion .\n",
            "Predicted POS : DET NOUN NOUN ADP NOUN ADP DET NOUN ADP NOUN ADJ _ ADP DET NOUN NUM AUX VERB ADP DET NOUN NOUN ADJ DET NOUN PUNCT\n",
            "---\n",
            "Sentence : L' adjudication pour les mesures prises dans le cadre de ces programmes devra avoir lieu dans les deux années qui suivront .\n",
            "Predicted POS : DET NOUN ADP DET NOUN ADJ ADP DET NOUN ADP DET NOUN ADJ VERB NOUN ADP DET NOUN NOUN PRON VERB PUNCT\n",
            "---\n",
            "Sentence : Aucune prolongation du de le délai d' adjudication n' est accordée .\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN ADP NOUN PART AUX VERB PUNCT\n",
            "---\n",
            "Sentence : À titre exceptionnel et dans des cas dûment justifiés , une prolongation limitée de la durée peut être accordée pour l' exécution des de les contrats .\n",
            "Predicted POS : ADP VERB VERB CCONJ ADP DET NOUN ADJ ADJ PUNCT DET NOUN ADV ADP DET NOUN VERB AUX VERB ADP DET NOUN _ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Pour ce qui concerne les frais d' audit et d' évaluation , les fonds de préadhésion prévus peuvent être engagés jusqu' à cinq ans après l' adhésion .\n",
            "Predicted POS : ADP PRON PRON VERB DET NOUN ADP NOUN CCONJ ADP NOUN PUNCT DET NOUN ADP NOUN ADJ VERB AUX ADV ADP ADP NOUN NOUN ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Cependant , les dispositions prévues à l' article 165 du de le règlement financier applicable au à le budget général des de les communautés européennes ne s' appliquent pas .\n",
            "Predicted POS : NOUN PUNCT DET NOUN VERB ADP DET NOUN ADJ _ ADP DET NOUN ADJ ADJ _ ADP DET NOUN ADJ _ ADP DET NOUN ADJ PART PRON VERB ADV PUNCT\n",
            "---\n",
            "Sentence : La commission peut arrêter les modalités de mise en œuvre de l' assistance visée au à le paragraphe 2 .\n",
            "Predicted POS : DET NOUN VERB VERB DET NOUN ADP NOUN ADP NOUN ADP DET NOUN ADJ _ ADP DET NOUN NUM PUNCT\n",
            "---\n",
            "Sentence : À cet effet , la commission est assistée par un comité .\n",
            "Predicted POS : ADP DET NOUN PUNCT DET NOUN AUX VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le comité adopte son règlement intérieur .\n",
            "Predicted POS : DET NOUN VERB DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Cette aide finance des projets de renforcement des de les institutions et de petits investissements limités qui sont accessoires à ceux-ci .\n",
            "Predicted POS : DET NOUN ADJ _ NOUN ADP NOUN _ ADP DET NOUN CCONJ ADP VERB ADJ ADJ PRON AUX VERB ADP VERB PUNCT\n",
            "---\n",
            "Sentence : Les crédits sont autorisés par l' autorité budgétaire dans la limite des de les perspectives financières .\n",
            "Predicted POS : DET NOUN AUX ADV ADP DET NOUN ADJ ADP DET NOUN _ ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : un douzième de chaque montant annuel est versé à la Bulgarie et à la Roumanie le premier jour ouvrable de chaque mois de l' année correspondante .\n",
            "Predicted POS : DET NOUN ADP NOUN NOUN ADJ AUX VERB ADP DET NOUN CCONJ ADP DET NOUN DET NOUN NOUN VERB ADP NOUN NOUN ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Les paiements forfaitaires sont utilisés dans les trois ans à compter de la date du de le premier décaissement .\n",
            "Predicted POS : DET NOUN ADJ AUX PRON ADP DET NOUN NOUN ADP VERB ADP DET NOUN _ ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Toute somme inutilisée ou dépensée de manière injustifiable est recouvrée par la commission .\n",
            "Predicted POS : DET NOUN ADJ CCONJ NOUN ADP NOUN ADJ AUX VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : La commission peut adopter les dispositions techniques nécessaires au à le fonctionnement de la facilité de trésorerie et de la facilité Schengen temporaires .\n",
            "Predicted POS : DET NOUN VERB VERB DET NOUN ADJ ADJ _ ADP DET NOUN ADP DET NOUN ADP NOUN CCONJ ADP DET NOUN ADJ ADJ PUNCT\n",
            "---\n",
            "Sentence : Les mesures ainsi décidées sont immédiatement applicables , tiennent compte des de les intérêts de toutes les parties concernées et n' entraînent pas de contrôles aux à les frontières .\n",
            "Predicted POS : DET NOUN ADV VERB AUX VERB ADJ PUNCT VERB NOUN _ ADP DET NOUN ADP DET DET NOUN ADJ CCONJ PART VERB ADV ADP NOUN _ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Les mesures qui causent le moins de perturbation au à le fonctionnement du de le marché intérieur devront être choisies en priorité .\n",
            "Predicted POS : DET NOUN PRON VERB DET NOUN ADP NOUN _ ADP DET NOUN _ ADP DET NOUN ADJ VERB AUX VERB ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Ces mesures de sauvegarde ne peuvent pas être utilisées comme moyen de discrimination arbitraire ou de restriction déguisée des de les échanges commerciaux entre les États membres .\n",
            "Predicted POS : DET NOUN ADP NOUN PART VERB ADV AUX VERB ADP NOUN ADP NOUN VERB CCONJ ADP VERB ADJ _ ADP DET NOUN ADJ ADP DET NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Les mesures sont maintenues pendant la durée strictement nécessaire et , en tout état de cause , sont levées lorsque l' engagement correspondant est rempli .\n",
            "Predicted POS : DET NOUN AUX VERB ADP DET NOUN ADJ NOUN CCONJ PUNCT ADP DET NOUN ADP NOUN PUNCT AUX VERB VERB DET NOUN ADJ AUX VERB PUNCT\n",
            "---\n",
            "Sentence : Elles peuvent cependant être appliquées au-delà de la période visée au à le premier alinéa tant que les engagements correspondants n' ont pas été remplis .\n",
            "Predicted POS : PRON VERB VERB AUX VERB VERB ADP DET NOUN ADJ _ ADP DET NOUN NOUN ADV SCONJ DET NOUN ADJ PART AUX ADV AUX VERB PUNCT\n",
            "---\n",
            "Sentence : La commission peut adapter les mesures arrêtées en fonction de la mesure dans laquelle le nouvel état membre concerné remplit ses engagements .\n",
            "Predicted POS : DET NOUN VERB VERB DET NOUN ADJ ADP NOUN ADP DET NOUN ADP VERB DET NOUN NOUN NOUN ADJ ADJ DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Les mesures sont maintenues pendant la durée strictement nécessaire et , en tout état de cause , sont levées dès que le manquement constaté est corrigé .\n",
            "Predicted POS : DET NOUN AUX VERB ADP DET NOUN ADJ NOUN CCONJ PUNCT ADP DET NOUN ADP NOUN PUNCT AUX VERB AUX SCONJ DET NOUN ADJ AUX VERB PUNCT\n",
            "---\n",
            "Sentence : Elles peuvent cependant être appliquées au-delà de la période visée au à le premier alinéa tant que ces manquements persistent .\n",
            "Predicted POS : PRON VERB VERB AUX VERB VERB ADP DET NOUN ADJ _ ADP DET NOUN NOUN ADV SCONJ DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Une loi européenne du de le conseil peut prolonger cette période .\n",
            "Predicted POS : DET NOUN PROPN _ ADP DET NOUN VERB VERB DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Ces mesures sont adoptées durant une période de trois ans à compter de la date d' adhésion et ne s' appliquent pas au-delà de cette période .\n",
            "Predicted POS : DET NOUN AUX VERB PRON DET NOUN ADP NOUN NOUN ADP VERB ADP DET NOUN ADP NOUN CCONJ PART PRON VERB ADV VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le parlement européen apporte à son règlement intérieur les adaptations rendues nécessaires par l' adhésion .\n",
            "Predicted POS : DET NOUN ADJ ADJ ADP DET NOUN ADJ DET NOUN ADJ ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le conseil apporte à son règlement intérieur les adaptations rendues nécessaires par l' adhésion .\n",
            "Predicted POS : DET NOUN VERB ADP DET NOUN ADJ DET NOUN ADJ ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Un ressortissant de chaque nouvel état membre est nommé à la commission à compter de la date d' adhésion .\n",
            "Predicted POS : DET NOUN ADP NOUN ADJ NOUN NOUN AUX VERB ADP DET NOUN ADP VERB ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Le mandat des de les membres ainsi nommés expire en même temps que celui des de les membres qui sont en fonction au à le moment de l' adhésion .\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN ADV ADJ ADJ ADP ADV NOUN SCONJ PRON DET ADP DET NOUN PRON AUX ADP VERB _ ADP DET NOUN ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Deux juges sont nommés à la Cour de justice et deux juges sont nommés au à le tribunal .\n",
            "Predicted POS : NUM NOUN AUX VERB ADP DET NOUN ADP NOUN CCONJ NOUN NOUN AUX VERB _ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le mandat de l' un des de les juges de la Cour de justice nommés conformément au à le paragraphe 1 expire le 6 octobre 2009 .\n",
            "Predicted POS : DET NOUN ADP DET NOUN _ ADP DET NOUN ADP DET NOUN ADP NOUN ADJ ADV _ ADP DET NOUN NUM NOUN DET NOUN NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Ce juge est désigné par le sort .\n",
            "Predicted POS : PRON NOUN AUX VERB ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le mandat de l' autre juge expire le 6 octobre 2012 .\n",
            "Predicted POS : DET NOUN ADP DET NOUN NOUN ADJ DET NOUN NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Le mandat de l' un des de les juges du de le tribunal nommés conformément au à le paragraphe 1 expire le 31 août 2007 .\n",
            "Predicted POS : DET NOUN ADP DET NOUN _ ADP DET NOUN _ ADP DET NOUN ADJ ADV _ ADP DET NOUN NUM NOUN DET NOUN ADJ ADJ PUNCT\n",
            "---\n",
            "Sentence : Le mandat de l' autre juge expire le 31 août 2010 .\n",
            "Predicted POS : DET NOUN ADP DET NOUN NOUN ADJ DET NOUN ADJ ADJ PUNCT\n",
            "---\n",
            "Sentence : La Cour de justice apporte à son règlement de procédure les adaptations rendues nécessaires par l' adhésion .\n",
            "Predicted POS : DET NOUN ADP NOUN ADJ ADP DET NOUN ADP NOUN DET NOUN ADJ ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le tribunal , en accord avec la Cour de justice , apporte à son règlement de procédure les adaptations rendues nécessaires par l' adhésion .\n",
            "Predicted POS : DET NOUN PUNCT ADP NOUN ADP DET NOUN ADP NOUN PUNCT VERB ADP DET NOUN ADP NOUN DET NOUN ADJ ADJ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Les règlements de procédure ainsi adaptés sont soumis à l' approbation du de le conseil .\n",
            "Predicted POS : DET NOUN ADP NOUN ADV ADJ AUX VERB ADP DET NOUN _ ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Un ressortissant de chaque nouvel état membre est nommé à la Cour des de les comptes à compter de la date d' adhésion pour un mandat de six ans .\n",
            "Predicted POS : DET NOUN ADP NOUN ADJ NOUN NOUN AUX VERB ADP DET NOUN _ ADP DET NOUN ADP VERB ADP DET NOUN ADP NOUN ADP DET NOUN ADP NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Le mandat des de les membres ainsi nommés expire en même temps que celui des de les membres qui sont en fonction au à le moment de l' adhésion .\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN ADV ADJ ADJ ADP ADV NOUN SCONJ PRON DET ADP DET NOUN PRON AUX ADP VERB _ ADP DET NOUN ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Le mandat des de les nouveaux membres nommés expire en même temps que celui des de les membres qui sont en fonction au à le moment de l' adhésion .\n",
            "Predicted POS : DET NOUN _ ADP DET NOUN NOUN VERB VERB ADP ADV NOUN SCONJ PRON DET ADP DET NOUN PRON AUX ADP VERB _ ADP DET NOUN ADP DET NOUN PUNCT\n",
            "---\n",
            "Sentence : Ils communiquent ces mesures à la commission au à le plus tard à la date d' adhésion ou , ultérieurement , dans le délai prévu dans le présent protocole .\n",
            "Predicted POS : PRON VERB DET NOUN ADP DET NOUN _ ADP DET ADV ADJ ADP DET NOUN ADP NOUN CCONJ PUNCT NOUN PUNCT ADP DET NOUN ADJ ADP DET ADJ NOUN PUNCT\n",
            "---\n",
            "Sentence : Ces mesures sont adoptées conformément aux à les règles de vote applicables à l' adoption de l' acte pour lequel une dérogation temporaire est demandée .\n",
            "Predicted POS : DET NOUN AUX VERB ADV _ ADP DET NOUN ADP NOUN ADJ ADP DET NOUN ADP DET NOUN ADP VERB DET NOUN ADJ AUX VERB PUNCT\n",
            "---\n",
            "Sentence : Lorsque ces dérogations sont arrêtées après l' adhésion , elles peuvent être appliquées à compter de la date d' adhésion .\n",
            "Predicted POS : SCONJ DET NOUN AUX VERB ADP DET NOUN PUNCT PRON VERB AUX VERB ADP VERB ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Lorsque ces adaptations sont adoptées après l' adhésion , elles peuvent être appliquées à compter de la date d' adhésion .\n",
            "Predicted POS : SCONJ DET NOUN AUX VERB ADP DET NOUN PUNCT PRON VERB AUX VERB ADP VERB ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Ils sont publiés au à le journal officiel de l' Union Européenne dans les cas où les textes dans les langues actuelles ont fait l' objet d' une telle publication .\n",
            "Predicted POS : PRON AUX VERB _ ADP DET NOUN ADJ ADP DET PROPN PROPN ADP DET NOUN PRON DET NOUN ADP DET NOUN ADJ AUX VERB DET NOUN ADP DET ADJ ADJ PUNCT\n",
            "---\n",
            "Sentence : Les annexes I à IX et les appendices font partie intégrante du de le présent protocole .\n",
            "Predicted POS : DET NOUN ADJ ADP VERB CCONJ DET NOUN ADJ NOUN ADJ _ ADP DET ADJ NOUN PUNCT\n",
            "---\n",
            "Sentence : Le texte de ce traité , établi en langues bulgare et roumaine , est joint au à le présent protocole .\n",
            "Predicted POS : DET NOUN ADP DET NOUN PUNCT VERB ADP NOUN ADJ CCONJ ADJ PUNCT AUX VERB _ ADP DET ADJ NOUN PUNCT\n",
            "---\n",
            "Sentence : Ces textes font foi dans les mêmes conditions que les textes du de le traité visé au à le premier alinéa , établis dans les langues actuelles .\n",
            "Predicted POS : DET NOUN ADV VERB ADP DET NOUN NOUN SCONJ DET NOUN _ ADP DET NOUN ADJ _ ADP DET NOUN NOUN PUNCT VERB ADP DET NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Tant que cet accord n' est pas conclu , dans la mesure où il s' applique provisoirement .\n",
            "Predicted POS : ADV SCONJ DET NOUN PART AUX ADV VERB PUNCT ADP DET NOUN PRON PRON PRON VERB VERB PUNCT\n",
            "---\n",
            "Sentence : Il est institué une superficie de base nationale pour chaque état membre producteur .\n",
            "Predicted POS : PRON AUX VERB DET NOUN ADP NOUN NOUN ADP ADJ NOUN NOUN ADJ PUNCT\n",
            "---\n",
            "Sentence : Toutefois , pour la France , deux superficies de base sont établies .\n",
            "Predicted POS : ADP PUNCT ADP DET NOUN PUNCT NUM ADJ ADP NOUN AUX VERB PUNCT\n",
            "---\n",
            "Sentence : une superficie maximale garantie de 829229 ha est ainsi établie .\n",
            "Predicted POS : DET NOUN ADJ ADJ ADP NOUN ADJ AUX ADV ADV PUNCT\n",
            "---\n",
            "Sentence : Si une telle décision est prise avant la date d' adhésion , elle ne sera appliquée qu' à la date d' adhésion .\n",
            "Predicted POS : SCONJ DET NOUN NOUN AUX VERB ADP DET NOUN ADP NOUN PUNCT ADJ PART AUX VERB SCONJ ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Les mesures d' aide sont notifiées à la commission dans un délai de quatre mois à compter de la date d' adhésion .\n",
            "Predicted POS : DET NOUN ADP VERB AUX VERB ADP DET NOUN ADP DET NOUN ADP NOUN NOUN ADP VERB ADP DET NOUN ADP NOUN PUNCT\n",
            "---\n",
            "Sentence : Cette notification comporte des informations sur la base juridique de chaque mesure .\n",
            "Predicted POS : DET NOUN ADJ _ NOUN ADP DET NOUN ADJ ADP NOUN NOUN PUNCT\n",
            "---\n",
            "Sentence : Une fois ce délai écoulé , toute aide jugée incompatible avec ces orientations est considérée comme une aide nouvelle .\n",
            "Predicted POS : DET NOUN PRON NOUN ADJ PUNCT DET NOUN ADJ ADJ ADP DET NOUN AUX VERB ADP DET ADJ ADJ PUNCT\n",
            "---\n",
            "Sentence : Les stocks visés au à le point 1 sont déduits de la quantité excédant le report normal de stocks .\n",
            "Predicted POS : DET NOUN ADJ _ ADP DET NOUN NUM AUX VERB ADP DET NOUN ADJ DET NOUN ADJ ADP NOUN PUNCT\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_metrics(model, dataloader, device, UNK_ID, PAD_ID=0):\n",
        "    model.eval()\n",
        "    all_preds, all_tags = [], []\n",
        "    oov_preds, oov_tags = [], []\n",
        "    known_preds, known_tags = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for words, tags in dataloader:\n",
        "            words = words.to(device)\n",
        "            tags = tags.to(device)\n",
        "            outputs = model(words)  # shape : (batch_size, seq_len, tagset_size)\n",
        "            predictions = outputs.argmax(dim=-1)  # (batch_size, seq_len)\n",
        "\n",
        "            # Parcourir chaque batch et chaque token\n",
        "            for i in range(words.shape[0]):\n",
        "                for j in range(words.shape[1]):\n",
        "                    # Ignorer le padding\n",
        "                    if tags[i, j].item() == PAD_ID:\n",
        "                        continue\n",
        "                    pred = predictions[i, j].item()\n",
        "                    true = tags[i, j].item()\n",
        "                    all_preds.append(pred)\n",
        "                    all_tags.append(true)\n",
        "\n",
        "                    # Si le token est OOV (celui-ci a été encodé par UNK_ID)\n",
        "                    if words[i, j].item() == UNK_ID:\n",
        "                        oov_preds.append(pred)\n",
        "                        oov_tags.append(true)\n",
        "                    else:\n",
        "                        known_preds.append(pred)\n",
        "                        known_tags.append(true)\n",
        "\n",
        "    overall_acc = accuracy_score(all_tags, all_preds)\n",
        "    overall_f1 = f1_score(all_tags, all_preds, average=\"macro\")\n",
        "\n",
        "    known_acc = accuracy_score(known_tags, known_preds) if known_tags else 0.0\n",
        "    known_f1 = f1_score(known_tags, known_preds, average=\"macro\") if known_tags else 0.0\n",
        "\n",
        "    oov_acc = accuracy_score(oov_tags, oov_preds) if oov_tags else 0.0\n",
        "    oov_f1 = f1_score(oov_tags, oov_preds, average=\"macro\") if oov_tags else 0.0\n",
        "\n",
        "    return {\n",
        "        \"overall_accuracy\": overall_acc,\n",
        "        \"overall_f1\": overall_f1,\n",
        "        \"known_accuracy\": known_acc,\n",
        "        \"known_f1\": known_f1,\n",
        "        \"oov_accuracy\": oov_acc,\n",
        "        \"oov_f1\": oov_f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "tH4h8kmsssBW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    dev_loss, dev_accuracy = evaluate(model, dev_loader, criterion, device)\n",
        "\n",
        "    # Calcul des métriques détaillées (accuracy et F1 global, sur tokens connus et OOV)\n",
        "    metrics = evaluate_metrics(model, dev_loader, device, UNK_ID, PAD_ID)\n",
        "\n",
        "    print(f\"Epoch {epoch}: train loss = {train_loss:.4f}, dev loss = {dev_loss:.4f}, dev accuracy = {dev_accuracy:.4f}\")\n",
        "    print(\"Overall Accuracy: {:.4f}, Overall F1: {:.4f}\".format(metrics[\"overall_accuracy\"], metrics[\"overall_f1\"]))\n",
        "    print(\"Known Accuracy: {:.4f}, Known F1: {:.4f}\".format(metrics[\"known_accuracy\"], metrics[\"known_f1\"]))\n",
        "    print(\"OOV Accuracy: {:.4f}, OOV F1: {:.4f}\".format(metrics[\"oov_accuracy\"], metrics[\"oov_f1\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwiIfvBPs9Z5",
        "outputId": "450915ca-e8c7-4128-d95f-bdfd6ed5b317"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss = 0.4157, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 2: train loss = 0.4287, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 3: train loss = 0.4203, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 4: train loss = 0.4166, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 5: train loss = 0.4215, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 6: train loss = 0.4207, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 7: train loss = 0.4184, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 8: train loss = 0.4188, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 9: train loss = 0.4194, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n",
            "Epoch 10: train loss = 0.4242, dev loss = 0.4882, dev accuracy = 0.8540\n",
            "Overall Accuracy: 0.8540, Overall F1: 0.6931\n",
            "Known Accuracy: 0.8936, Known F1: 0.7704\n",
            "OOV Accuracy: 0.7020, OOV F1: 0.2289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from conllu import parse_incr\n",
        "\n",
        "# Définir l'appareil (GPU si disponible)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Charger le modèle et les vocabulaires (assurez-vous que load_model est défini dans le notebook)\n",
        "model, Vw, Vi = load_model(\"/content/pos_tagger.pt\", device)\n",
        "\n",
        "# Ouvrir le fichier de prédictions en écriture\n",
        "with open(\"/content/pred.conllu\", \"w\", encoding=\"utf-8\") as outf:\n",
        "    # Lire le fichier de test\n",
        "    with open(\"/content/fr_partut-ud-test.conllu\", \"r\", encoding=\"utf-8\") as f:\n",
        "        for sentence in parse_incr(f):\n",
        "            # Prédire les POS pour la phrase\n",
        "            predicted_tags = predict_sentence(model, sentence, Vw, Vi, device)\n",
        "            # Mettre à jour le champ \"upos\" de chaque token avec la prédiction\n",
        "            for token, tag in zip(sentence, predicted_tags):\n",
        "                token[\"upos\"] = tag\n",
        "            # Écrire la phrase au format CoNLL-U dans le fichier de prédictions\n",
        "            outf.write(sentence.serialize())\n",
        "            outf.write(\"\\n\")\n",
        "\n",
        "# Lancer l'évaluation avec accuracy.py\n",
        "!python accuracy.py -p pred.conllu -g fr_partut-ud-test.conllu -t fr_partut-ud-train.conllu -c upos -f form\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVXgkN5Qxrdu",
        "outputId": "3c5d8c10-1c22-4eef-c067-703165e82746"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0fb7f0e20024>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(model_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions file: pred.conllu\n",
            "Accuracy on all upos: 86.07 ( 2317/ 2692)\n",
            "Accuracy on OOV upos: 61.00 (  183/  300)\n"
          ]
        }
      ]
    }
  ]
}